{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRmKjr8zFDmH",
        "outputId": "df8cdab4-c90a-4173-834e-147e9e8cb88e"
      },
      "outputs": [],
      "source": [
        "pip install music21 tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YLT12hJtFFdx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Activation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import glob\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHGRNbljFL85",
        "outputId": "de5f32fb-fa3f-4ef8-e3b5-9e52a925c0be"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pickle\n",
        "from music21 import converter, instrument, note, chord\n",
        "\n",
        "songs_path   = '/Users/monilshah/Documents/02_NWU/09_MSDS_458_DL/99_group_project/LSTMMusic/midi_songs/'\n",
        "\n",
        "def get_notes():\n",
        "    notes = []\n",
        "\n",
        "    # Path to your MIDI files stored in Google Drive\n",
        "    for file in glob.glob(songs_path + \"*.mid\"):\n",
        "        midi = converter.parse(file)\n",
        "        print(f\"Parsing {file}\")\n",
        "\n",
        "        parts = instrument.partitionByInstrument(midi)\n",
        "        if parts:\n",
        "            notes_to_parse = parts.parts[0].recurse()\n",
        "        else:\n",
        "            notes_to_parse = midi.flat.notes\n",
        "\n",
        "        for element in notes_to_parse:\n",
        "            if isinstance(element, note.Note):\n",
        "                notes.append(str(element.pitch))\n",
        "            elif isinstance(element, chord.Chord):\n",
        "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    # Save notes to a pickle file\n",
        "    with open('notes.pkl', 'wb') as f:\n",
        "        pickle.dump(notes, f)\n",
        "\n",
        "    return notes\n",
        "\n",
        "# Generate the notes.pkl file\n",
        "get_notes()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SoBVIe4XFQ5z"
      },
      "outputs": [],
      "source": [
        "def prepare_sequences(notes, n_vocab):\n",
        "    sequence_length = 100  # Length of each training sequence\n",
        "\n",
        "    # Map unique notes to integers\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    # Prepare input and output sequences\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    for i in range(0, len(notes) - sequence_length):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # Reshape for LSTM: (number of sequences, sequence length, 1)\n",
        "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # Normalize input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "\n",
        "    network_output = to_categorical(network_output, num_classes=n_vocab)\n",
        "\n",
        "    return network_input, network_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "qVPaASslFUky"
      },
      "outputs": [],
      "source": [
        "def create_model(network_input, n_vocab):\n",
        "    model = Sequential()\n",
        "\n",
        "    # LSTM layer\n",
        "    model.add(LSTM(64, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n",
        "    #model.add(Dropout(0.1))\n",
        "    \n",
        "    model.add(LSTM(64, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n",
        "    #model.add(Dropout(0.1))\n",
        "    \n",
        "    model.add(LSTM(64, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n",
        "    #model.add(Dropout(0.1))\n",
        "    \n",
        "    model.add(LSTM(64, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n",
        "    #model.add(Dropout(0.1))\n",
        "    \n",
        "    #model.add(LSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n",
        "    #model.add(LSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n",
        "    #model.add(LSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n",
        "    #model.add(LSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n",
        "    #model.add(LSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n",
        "    #model.add(LSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n",
        "\n",
        "    # Another LSTM layer\n",
        "    model.add(LSTM(512, return_sequences=False))\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "    # Fully connected layer\n",
        "    model.add(Dense(256))\n",
        "    model.add(Dropout(0.1))\n",
        "    \n",
        "    # Fully connected layer\n",
        "    model.add(Dense(128))\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(n_vocab, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "oE-MDpenKAt5"
      },
      "outputs": [],
      "source": [
        "# def create_network(input_shape):\n",
        "#     \"\"\"Build the LSTM model.\"\"\"\n",
        "#     model = Sequential()\n",
        "\n",
        "#     # Add LSTM layers\n",
        "#     model.add(LSTM(256, input_shape=(input_shape[1], input_shape[2]), return_sequences=True))\n",
        "#     model.add(Dropout(0.3))\n",
        "\n",
        "#     model.add(LSTM(256, return_sequences=False))\n",
        "#     model.add(Dropout(0.3))\n",
        "\n",
        "#     # Add Dense layers\n",
        "#     model.add(Dense(256))\n",
        "#     model.add(Dropout(0.3))\n",
        "\n",
        "#     model.add(Dense(128))\n",
        "#     model.add(Dense(88))  # 88 possible notes\n",
        "\n",
        "#     # Final activation\n",
        "#     model.add(Activation('softmax'))\n",
        "\n",
        "#     # Compile the model\n",
        "#     model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "#     return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "HL1FjNdqKEhd"
      },
      "outputs": [],
      "source": [
        "def train_model(model, network_input, network_output, epochs=200, batch_size=64):\n",
        "    \"\"\"Train the model with callbacks.\"\"\"\n",
        "\n",
        "    # Define callback functions\n",
        "    checkpoint = ModelCheckpoint(\n",
        "         'weights-improvement-{epoch:02d}-{loss:.4f}-bigger.keras',\n",
        "        monitor='loss',\n",
        "        verbose=1,\n",
        "        save_best_only=True,\n",
        "        mode='min'\n",
        "    )\n",
        "\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='loss',\n",
        "        patience=2,\n",
        "        verbose=1,\n",
        "        mode='min',\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='loss',\n",
        "        factor=0.2,\n",
        "        patience=2,\n",
        "        min_lr=0.001,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        network_input,\n",
        "        network_output,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[checkpoint, early_stopping, reduce_lr]\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dC-3R2mLc0R",
        "outputId": "b1c06f61-e678-4196-9fdd-9a340cb3aebb"
      },
      "outputs": [],
      "source": [
        "# Load notes from the saved file\n",
        "with open('notes.pkl', 'rb') as f:\n",
        "    notes = pickle.load(f)\n",
        "\n",
        "#Get the number of unique notes\n",
        "n_vocab = len(set(notes))\n",
        "\n",
        "# Prepare sequences for LSTM\n",
        "network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "# Create the LSTM model\n",
        "model = create_model(network_input, n_vocab)\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'weights-improvement-{epoch:02d}-{loss:.4f}.keras',  # Save the best model with the extension .keras\n",
        "    monitor='loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='loss',\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    mode='min',\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='loss',\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    min_lr=0.0001,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model with callbacks\n",
        "model.fit(\n",
        "    network_input,\n",
        "    network_output,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TG3qHdJ4FdgJ"
      },
      "outputs": [],
      "source": [
        "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
        "    start = np.random.randint(0, len(network_input) - 1)\n",
        "\n",
        "    # Initial input sequence for the model\n",
        "    pattern = network_input[start]\n",
        "    generated_notes = []\n",
        "\n",
        "    # Generate 500 notes\n",
        "    for note_index in range(500):\n",
        "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "        index = np.argmax(prediction)\n",
        "        result = pitchnames[index]\n",
        "        generated_notes.append(result)\n",
        "\n",
        "        # Update pattern\n",
        "        pattern = np.append(pattern, index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    return generated_notes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uhcx2XikFgqu"
      },
      "outputs": [],
      "source": [
        "def create_midi(generated_notes):\n",
        "    output_notes = []\n",
        "\n",
        "    for pattern in generated_notes:\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(int(current_note))\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            output_notes.append(new_chord)\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp='midi_output/generated_music_v1.mid')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VQrMJvO0FjTA"
      },
      "outputs": [],
      "source": [
        "# Load notes, prepare sequences, and train the model (as shown before)\n",
        "n_vocab = len(set(notes))\n",
        "#network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "#model = create_model(network_input, n_vocab)\n",
        "#model.fit(network_input, network_output, epochs=200, batch_size=64)\n",
        "\n",
        "# Generate music\n",
        "pitchnames = sorted(set(item for item in notes))\n",
        "generated_notes = generate_notes(model, network_input, pitchnames, n_vocab)\n",
        "\n",
        "# Convert generated notes to MIDI file\n",
        "create_midi(generated_notes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Conda_310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
